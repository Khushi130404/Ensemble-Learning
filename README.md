# Ensemble_Learning

This project demonstrates various ensemble learning techniques using Jupyter Notebook. The goal is to explore how ensemble methods can improve the performance of machine learning models for both regression and classification tasks.

## Techniques Covered

The following ensemble methods have been implemented and evaluated in this project :
- Adaboost (Adaptive Boosting)
- Bagging (Bootstrap Aggregating)
- Gradient Boosting
- Random Forest
- Stacking Ensemble
- Voting Ensemble

## Problem Types

The project includes implementations for :

- Regression Problems

- Classification Problems

## Project Structure

The project is organized into the following sections :

### 1. Data Preprocessing
   
- Loading datasets
- Handling missing values

### 2. Feature scaling
   
- Model Implementation
- Implementing each ensemble technique for regression and classification tasks

### 3. Model Evaluation

- Comparing model performance using metrics such as:
  - For Regression: Mean Squared Error (MSE), R-Squared (RÂ²)
  - For Classification: Accuracy, Precision, Recall, F1-Score



